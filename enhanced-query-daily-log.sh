#!/bin/bash

# Enhanced Daily Log Query Script with better UX
# Improved version with progress indicators and validation

# Color codes
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Helper functions
print_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_step() {
    echo -e "${CYAN}[STEP $1]${NC} $2"
}

# Progress bar function
show_progress() {
    local duration=$1
    local sleep_interval=1
    local progress=0
    local bar_length=50
    
    while [ $progress -le $duration ]; do
        local percentage=$((progress * 100 / duration))
        local filled_length=$((progress * bar_length / duration))
        local bar=$(printf "%${filled_length}s" | tr ' ' 'â–ˆ')
        local empty=$(printf "%$((bar_length - filled_length))s" | tr ' ' 'â–‘')
        
        printf "\r${CYAN}é€²åº¦:${NC} [%s%s] %d%% (%d/%d ç§’)" "$bar" "$empty" "$percentage" "$progress" "$duration"
        
        sleep $sleep_interval
        progress=$((progress + sleep_interval))
    done
    echo
}

# Generate folder name from URL path
generate_folder_from_url() {
    local url=$1
    
    # Remove protocol (http:// or https://)
    local path=$(echo "$url" | sed 's|^https*://||')
    
    # Remove domain name, keep only path
    path=$(echo "$path" | sed 's|^[^/]*||')
    
    # Remove leading and trailing slashes
    path=$(echo "$path" | sed 's|^/||' | sed 's|/$||')
    
    # Replace slashes with hyphens for folder name
    path=$(echo "$path" | sed 's|/|-|g')
    
    # Special mapping for common paths
    case "$path" in
        "category-1") echo "L1" ;;
        "category-2") echo "L2" ;;
        "category-3") echo "L3" ;;
        "category-4") echo "L4" ;;
        "category-5") echo "L5" ;;
        "") echo "root" ;;
        *) echo "$path" ;;
    esac
}

# Generate filename from URL
generate_filename_from_url() {
    local url=$1
    local date=$2
    
    # Remove protocol (http:// or https://)
    local path=$(echo "$url" | sed 's|^https*://||')
    
    # Remove domain name, keep only path
    path=$(echo "$path" | sed 's|^[^/]*||')
    
    # Remove leading and trailing slashes
    path=$(echo "$path" | sed 's|^/||' | sed 's|/$||')
    
    # Replace slashes with hyphens
    path=$(echo "$path" | sed 's|/|-|g')
    
    # If path is empty, use 'root'
    if [ -z "$path" ]; then
        path="root"
    fi
    
    echo "log-${date}-${path}"
}

# Validate URL format
validate_url() {
    local url=$1
    
    # Check if URL starts with http:// or https://
    if [[ ! $url =~ ^https?:// ]]; then
        print_error "URL æ ¼å¼éŒ¯èª¤ï¼å¿…é ˆä»¥ http:// æˆ– https:// é–‹é ­"
        return 1
    fi
    
    # Check if URL contains domain
    if [[ ! $url =~ ^https?://[^/]+.*$ ]]; then
        print_error "URL æ ¼å¼éŒ¯èª¤ï¼å¿…é ˆåŒ…å«æœ‰æ•ˆçš„åŸŸå"
        return 1
    fi
    
    return 0
}

# Validate date format
validate_date() {
    local date=$1
    
    # Check if date matches YYYYMMDD format
    if [[ ! $date =~ ^[0-9]{8}$ ]]; then
        print_error "æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼æ‡‰ç‚º YYYYMMDD æ ¼å¼ (ä¾‹å¦‚: 20250821)"
        return 1
    fi
    
    # Extract year, month, day
    local year=${date:0:4}
    local month=${date:4:2}
    local day=${date:6:2}
    
    # Basic validation
    if [ $year -lt 2020 ] || [ $year -gt 2030 ]; then
        print_error "å¹´ä»½æ‡‰åœ¨ 2020-2030 ä¹‹é–“"
        return 1
    fi
    
    if [ $month -lt 1 ] || [ $month -gt 12 ]; then
        print_error "æœˆä»½æ‡‰åœ¨ 01-12 ä¹‹é–“"
        return 1
    fi
    
    if [ $day -lt 1 ] || [ $day -gt 31 ]; then
        print_error "æ—¥æœŸæ‡‰åœ¨ 01-31 ä¹‹é–“"
        return 1
    fi
    
    return 0
}

# Show usage
show_usage() {
    echo "ä½¿ç”¨æ–¹æ³•: $0 <date> <url> [folder]"
    echo ""
    echo "åƒæ•¸:"
    echo "  date    è¦æŸ¥è©¢çš„æ—¥æœŸ (æ ¼å¼: YYYYMMDD)"
    echo "  url     è¦æŸ¥è©¢çš„ç›®æ¨™URL (å¿…é ˆä»¥ http:// æˆ– https:// é–‹é ­)"
    echo "  folder  å¯é¸çš„è³‡æ–™å¤¾åç¨± (é è¨­æœƒæ ¹æ“šURLè‡ªå‹•ç”Ÿæˆ)"
    echo ""
    echo "ç¯„ä¾‹:"
    echo "  $0 20250821 https://www.eslite.com/category/2/"
    echo "  $0 20250821 https://www.eslite.com/category/2/ L2"
    echo "  $0 20250820 https://example.com/products/ products"
    echo ""
    echo "èªªæ˜:"
    echo "  æ­¤è…³æœ¬æœƒæŸ¥è©¢æŒ‡å®šæ—¥æœŸå’ŒURLçš„å…©ç¨®æ—¥èªŒ:"
    echo "  1. HTTP 200 å›æ‡‰æ—¥èªŒ (æ¸²æŸ“æ™‚é–“æ•¸æ“š)"
    echo "  2. User-Agent æ—¥èªŒ (ç”¨æˆ¶ä»£ç†æ•¸æ“š)"
    echo ""
    echo "è³‡æ–™å¤¾è‡ªå‹•æ˜ å°„:"
    echo "  å¦‚æœæœªæŒ‡å®šè³‡æ–™å¤¾ï¼ŒæœƒæŒ‰ä»¥ä¸‹è¦å‰‡è‡ªå‹•ç”Ÿæˆ:"
    echo "  - category/1 â†’ L1"
    echo "  - category/2 â†’ L2"
    echo "  - products/ â†’ products"
    echo "  - api/v1/users â†’ api-v1-users"
    echo ""
    echo "è¼¸å‡ºæª”æ¡ˆä½ç½®:"
    echo "  - ./to-analyze-daily-data/200-log/[folder]/<filename>.csv"
    echo "  - ./to-analyze-daily-data/user-agent-log/[folder]/user-agent-<filename>.csv"
}

# Check prerequisites
check_prerequisites() {
    print_step 1 "æª¢æŸ¥ç’°å¢ƒå…ˆæ±ºæ¢ä»¶"
    
    # Check if gcloud is installed
    if ! command -v gcloud &> /dev/null; then
        print_error "Google Cloud CLI æœªå®‰è£ï¼"
        print_info "è«‹å®‰è£ Google Cloud CLI: https://cloud.google.com/sdk/docs/install"
        return 1
    fi
    
    # Check if node is installed
    if ! command -v node &> /dev/null; then
        print_error "Node.js æœªå®‰è£ï¼"
        print_info "è«‹å®‰è£ Node.js: https://nodejs.org/"
        return 1
    fi
    
    # Check if google-cloud-log-query.js exists
    if [ ! -f "google-cloud-log-query.js" ]; then
        print_error "æ‰¾ä¸åˆ° google-cloud-log-query.js æª”æ¡ˆï¼"
        print_info "è«‹ç¢ºèªæ‚¨åœ¨æ­£ç¢ºçš„å°ˆæ¡ˆç›®éŒ„ä¸­åŸ·è¡Œæ­¤è…³æœ¬"
        return 1
    fi
    
    print_success "ç’°å¢ƒæª¢æŸ¥é€šé"
    return 0
}

# Check and refresh credentials
check_credentials() {
    print_step 2 "æª¢æŸ¥ Google Cloud èªè­‰"
    
    local credentials_file="$HOME/.config/gcloud/application_default_credentials.json"
    
    # Refresh Google Cloud credentials (once per day)
    if [ ! -f "$credentials_file" ] || [ $(find "$credentials_file" -mtime +1 2>/dev/null | wc -l) -gt 0 ]; then
        print_warning "Google Cloud èªè­‰å·²éæœŸæˆ–ä¸å­˜åœ¨ï¼Œæ­£åœ¨é‡æ–°èªè­‰..."
        if gcloud auth application-default login; then
            print_success "Google Cloud èªè­‰å®Œæˆ"
        else
            print_error "Google Cloud èªè­‰å¤±æ•—"
            return 1
        fi
    else
        print_success "Google Cloud èªè­‰æœ‰æ•ˆ (ä¸åˆ° 24 å°æ™‚)"
    fi
    
    return 0
}

# Create output directories
create_directories() {
    print_step 3 "æº–å‚™è¼¸å‡ºç›®éŒ„"
    
    local dirs=(
        "./to-analyze-daily-data/200-log/${folder_name}"
        "./to-analyze-daily-data/user-agent-log/${folder_name}"
    )
    
    for dir in "${dirs[@]}"; do
        if [ ! -d "$dir" ]; then
            mkdir -p "$dir"
            print_info "å·²å»ºç«‹ç›®éŒ„: $dir"
        fi
    done
    
    print_success "è¼¸å‡ºç›®éŒ„æº–å‚™å®Œæˆ"
    return 0
}

# Execute log query with progress
execute_query() {
    local query_type=$1
    local output_dir=$2
    local filename=$3
    local formatted_date=$4
    local search_condition=$5
    
    print_info "åŸ·è¡Œ $query_type æŸ¥è©¢..."
    print_info "è¼¸å‡ºç›®éŒ„: $output_dir"
    print_info "æª”æ¡ˆåç¨±: $filename"
    print_info "æŸ¥è©¢æ¢ä»¶: $search_condition"
    
    echo
    
    # Execute the query
    if node google-cloud-log-query.js --output-dir "$output_dir" --filename "$filename" "$formatted_date" "$search_condition"; then
        print_success "$query_type æŸ¥è©¢å®Œæˆ"
        
        # Show file info if it exists
        local output_file="$output_dir/$filename"
        if [ -f "$output_file" ]; then
            local file_size=$(du -h "$output_file" | cut -f1)
            local line_count=$(wc -l < "$output_file")
            print_info "è¼¸å‡ºæª”æ¡ˆ: $output_file"
            print_info "æª”æ¡ˆå¤§å°: $file_size"
            print_info "è¨˜éŒ„ç­†æ•¸: $((line_count - 1)) ç­† (ä¸å«æ¨™é¡Œåˆ—)"
        fi
        
        return 0
    else
        print_error "$query_type æŸ¥è©¢å¤±æ•—"
        return 1
    fi
}

# Main function
main() {
    echo
    print_info "ğŸ“Š Enhanced Daily Log Query Tool"
    echo "=================================="
    echo
    
    # Check arguments
    if [ $# -eq 0 ]; then
        print_error "ç¼ºå°‘å¿…è¦åƒæ•¸"
        echo
        show_usage
        exit 1
    fi
    
    if [ "$1" = "-h" ] || [ "$1" = "--help" ]; then
        show_usage
        exit 0
    fi
    
    if [ $# -lt 2 ]; then
        print_error "ç¼ºå°‘URLåƒæ•¸"
        echo
        show_usage
        exit 1
    fi
    
    local date=$1
    local url=$2
    local folder_name=$3  # å¯é¸çš„è³‡æ–™å¤¾åƒæ•¸
    
    # Validate date
    if ! validate_date "$date"; then
        echo
        show_usage
        exit 1
    fi
    
    # Validate URL
    if ! validate_url "$url"; then
        echo
        show_usage
        exit 1
    fi
    
    # Convert YYYYMMDD to YYYY-MM-DD format for query
    local formatted_date="${date:0:4}-${date:4:2}-${date:6:2}"
    
    # Determine folder name (use provided or auto-generate)
    if [ -n "$folder_name" ]; then
        print_info "ä½¿ç”¨æŒ‡å®šè³‡æ–™å¤¾: $folder_name"
    else
        folder_name=$(generate_folder_from_url "$url")
        print_info "è‡ªå‹•ç”Ÿæˆè³‡æ–™å¤¾: $folder_name"
    fi
    
    # Generate filename based on URL
    local filename_base=$(generate_filename_from_url "$url" "$date")
    
    print_info "æŸ¥è©¢æ—¥æœŸ: $formatted_date ($date)"
    print_info "æŸ¥è©¢URL: $url"
    print_info "è³‡æ–™å¤¾: $folder_name"
    print_info "æª”ååŸºç¤: $filename_base"
    echo
    
    # Check prerequisites
    if ! check_prerequisites; then
        exit 1
    fi
    
    echo
    
    # Check credentials
    if ! check_credentials; then
        exit 1
    fi
    
    echo
    
    # Create directories
    if ! create_directories; then
        exit 1
    fi
    
    echo
    print_step 4 "é–‹å§‹æ—¥èªŒæŸ¥è©¢"
    print_info "æ­¤éç¨‹å°‡åˆ†å…©å€‹æ­¥é©ŸåŸ·è¡Œï¼Œæ¯æ­¥é©Ÿä¹‹é–“æœƒç­‰å¾… 30 ç§’"
    echo
    
    # First execution: 200-log analysis
    print_step "4.1" "æŸ¥è©¢ HTTP 200 å›æ‡‰æ—¥èªŒ"
    local search_200="SEARCH(\"got 200 in ${url}\")"
    if ! execute_query \
        "HTTP 200 å›æ‡‰" \
        "./to-analyze-daily-data/200-log/${folder_name}" \
        "${filename_base}.csv" \
        "$formatted_date" \
        "$search_200"; then
        exit 1
    fi
    
    echo
    print_info "ç­‰å¾… 30 ç§’å¾ŒåŸ·è¡Œä¸‹ä¸€å€‹æŸ¥è©¢ (é¿å… API é™åˆ¶)..."
    show_progress 30
    echo
    
    # Second execution: user-agent-log analysis  
    print_step "4.2" "æŸ¥è©¢ User-Agent æ—¥èªŒ"
    local search_ua="SEARCH(\"\`X-Original-User-Agent:\` \`${url}\`\")"
    if ! execute_query \
        "User-Agent" \
        "./to-analyze-daily-data/user-agent-log/${folder_name}" \
        "user-agent-${filename_base}.csv" \
        "$formatted_date" \
        "$search_ua"; then
        exit 1
    fi
    
    echo
    print_success "ğŸ‰ æ‰€æœ‰æ—¥èªŒæŸ¥è©¢å®Œæˆï¼"
    echo
    print_info "ä¸‹ä¸€æ­¥: åŸ·è¡Œæ•¸æ“šåˆ†æ"
    echo "  npm run analyze-daily \"$date ~ $date\""
    echo "  æˆ–: ./daily-log-analysis-script.sh \"$date ~ $date\""
    echo
    print_info "ğŸ’¡ æç¤º: ä½¿ç”¨ workflow-guide.js ç²å¾—å®Œæ•´çš„äº’å‹•å¼æŒ‡å°"
    echo "  node workflow-guide.js"
}

# Run main function
main "$@"